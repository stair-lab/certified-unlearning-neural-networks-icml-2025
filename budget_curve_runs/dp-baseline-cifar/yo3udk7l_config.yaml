
dataset:
  name: "cifar10"
  input_shape: [32, 32, 3]
  root: "./data"
  batch_size: 128
  num_workers: 4
  val_split: 0.1
  forget_split: 0.1
  seed: 230

model:
  name: "tiny_net_cifar"
  n_classes: 10

training:
  epochs: 100
  optim: "SGD"
  max_lr: 0.05
  momentum: 0
  weight_decay: 0.05
  lr_schedule: "onecycle"
  pretrained: "logs/rpguqobg/ckpt"

unlearning:
  epochs: 50
  optim: "SGD"
  momentum: 0
  weight_decay: 10
  lr_schedule: "constant"
  noise_schedule: "constant"
  max_lr: 0.001
  init_model_clip: 0.1
  init_model_clip_type: "clip"
  init_sigma: 0
  algorithm: 'dp-baseline'
  delta: 0.00001
  dp-baseline:
    epsilon_target: 1

post_unlearning:
  optim: "SGD"
  momentum: 0
  weight_decay: 0.0005
  lr_schedule: "onecycle"
  max_lr: 0.1
  post_unlearn_clip: False

wandb:

  project: "unlearning-dp-f2"
  entity: "unlearning-dynamics"
  log_dir: "./wandb_logs"

secure_rng: False
save_every: 1
global_seed: 9153
