
dataset:
  name: "cifar10"
  input_shape: [32, 32, 3]
  root: "./data"
  batch_size: 128
  num_workers: 4
  val_split: 0.1
  forget_split: 0.1
  seed: 230

model:
  name: "tiny_net_cifar"
  n_classes: 10

training:
  epochs: 400
  optim: "SGD"
  max_lr: 0.06
  momentum: 0
  weight_decay: 0.0005
  lr_schedule: "onecycle"
  pretrained: "logs/iep18hnq/ckpt"

unlearning:
  epochs: 50
  optim: "SGD"
  momentum: 0
  weight_decay: 10
  lr_schedule: "constant"
  noise_schedule: "constant"
  max_lr: 0.00010000
  init_model_clip: 30
  init_model_clip_type: "clip"
  init_sigma: 0
  algorithm: 'contractive_coefficients'
  delta: 0.00001
  contractive_coefficients:
    epsilon_target: 1
    sigma: 0.5
    model_clip: 0.975
    grad_clip: False
    noise_addition_after_projection: True
    noise_addition_before_projection: False

post_unlearning:
  optim: "SGD"
  momentum: 0
  weight_decay: 0.0005
  lr_schedule: "onecycle"
  max_lr: 0.1
  post_unlearn_clip: False

wandb:
  project: "unlearning-dp-f2"
  entity: "unlearning-dynamics"
  log_dir: "./wandb_logs"

secure_rng: False
save_every: 1
global_seed: 9153
  